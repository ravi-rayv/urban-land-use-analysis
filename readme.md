# Urban Land-Use Classification Using Social Media Data

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status: Active](https://img.shields.io/badge/Status-Active-brightgreen)]()

## ğŸ“‹ Project Overview

This project classifies urban land-use types using **social media data** (Twitter/X) combined with **machine learning** and **geospatial analysis**. The workflow includes:

1. **Data Collection** - Scrape location-tagged tweets via Twitter API
2. **Geospatial Processing** - Extract coordinates and aggregate by geography
3. **Visualization** - Generate 12 types of geographic maps showing engagement patterns
4. **Analysis** - Identify land-use characteristics from social signals

### Key Features
- âœ… Streaming data pipeline (memory-efficient batch processing)
- âœ… Multi-authentication fallback (Bearer, X-API-Key, Direct Token)
- âœ… 12 geospatial visualization types (KDE, Voronoi, IDW, hexbin, etc.)
- âœ… City boundary overlay with customizable styling
- âœ… Modular, configurable architecture
- âœ… Production-ready error handling

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- Twitter API Token ([Get one here](https://developer.twitter.com/))
- City boundary shapefile (optional, but recommended)

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/urban-land-use-analysis.git
cd urban-land-use-analysis
```

### Step 2: Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

### 1. Edit `config.py`
Set your API token and file paths:
```python
TWITTER_API_TOKEN = "your_api_token_here"
SHAPEFILE_PATH = "data/shapefiles/City_Boundary.shp"
CSV_OUTPUT_FILENAME = "data/output/tweets_data.csv"
```

### 2. Edit `constants.py`
Define search locations and keywords:
```python
LOCATIONS = [
    {"geo": "19.0760,72.8777,0.5km", "name": "Mumbai_Central"},
    {"geo": "28.6139,77.2090,0.5km", "name": "Delhi_Central"},
]

KEYWORDS = ["House", "Shop", "School", "Hospital", "Park", ...]
```

---

## ğŸš€ Usage

### Step 1: Collect Tweet Data
```bash
python src/tweet_collector.py
```
**Output:** `data/output/tweets_data.csv`

Sample columns:
```
Query | Date | Tweet by | Text Content | Like Count | Reply Count | Tweet URL | Error
```

### Step 2: Generate Geographic Visualizations
```bash
python src/geo_visualizer.py
```
**Output:** 12 PNG maps in `data/output/maps/`

**Map Types Generated:**
1. **KDE Heatmap** - Smooth kernel density estimation
2. **Engagement Contours** - Isoline maps of tweet engagement
3. **Hexagonal Grid** - Aggregated engagement by hex cells
4. **Raster Grid** - Regular rectangular cell aggregation
5. **Voronoi Diagram** - Territory-based analysis
6. **Point Transparency** - Individual tweet visibility
7. **IDW Interpolation** - Inverse distance weighting surface
8. **Hot Spot Clustering** - Geographic clusters
9. **Temporal Heatmap** - Time-based engagement patterns
10. **Sentiment Map** - Emotional content distribution
11. **Keyword Frequency** - Spatial distribution of keywords
12. **Composite Overview** - Multi-layer analysis

---

## ğŸ“Š Data Flow

```
Twitter API
    â†“
tweet_collector.py (streaming pipeline)
    â†“
tweets_data.csv (cleaned, geocoded)
    â†“
geo_visualizer.py (12 visualizations)
    â†“
maps/ (PNG output with city boundary overlay)
```

---

## ğŸ“ Directory Structure

```
urban-land-use-analysis/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python packages
â”œâ”€â”€ config.py                 # User settings (API token, paths)
â”œâ”€â”€ constants.py              # Search locations & keywords
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tweet_collector.py    # Data collection script
â”‚   â”œâ”€â”€ geo_visualizer.py     # Visualization script
â”‚   â””â”€â”€ utils.py              # Shared utilities
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ shapefiles/       # Place your .shp files here
â”‚   â”œâ”€â”€ output/
â”‚   â”‚   â”œâ”€â”€ tweets/           # Generated CSV files
â”‚   â”‚   â””â”€â”€ maps/             # Generated PNG maps
â”‚   â””â”€â”€ raw/                  # Raw data before processing
â”‚
â”œâ”€â”€ notebooks/                # Jupyter analysis (optional)
â”‚   â””â”€â”€ analysis.ipynb
â”‚
â”œâ”€â”€ tests/                    # Unit tests (optional)
â”‚   â””â”€â”€ test_collector.py
â”‚
â”œâ”€â”€ .gitignore               # Git ignore file
â””â”€â”€ LICENSE                  # MIT License
```

---

## ğŸ”‘ API Configuration

### Twitter API Token
1. Visit [developer.twitter.com](https://developer.twitter.com/)
2. Create a new project and app
3. Generate "Bearer Token" from Keys & Tokens
4. Add to `config.py`:
   ```python
   TWITTER_API_TOKEN = "your_bearer_token_here"
   ```

### Alternative Authentication Methods
The collector automatically falls back to alternative auth methods:
- X-API-Key header
- Direct token
- Token authorization header

---

## ğŸ“ Shapefile Setup

### Finding Shapefiles
- [Natural Earth Data](https://www.naturalearthdata.com/)
- [OpenStreetMap/Geofabrik](http://download.geofabrik.de/)
- [Local government mapping agencies](https://www.openstreetmap.org/)

### Required Files
Place all files with the same name in `data/shapefiles/`:
```
data/shapefiles/
â”œâ”€â”€ City_Boundary.shp       # Main geometry file
â”œâ”€â”€ City_Boundary.shx       # Index file
â”œâ”€â”€ City_Boundary.dbf       # Attribute file
â””â”€â”€ City_Boundary.prj       # Projection file (optional but recommended)
```

### If No Shapefile Available
The visualizer will use the extent of your tweet data instead:
```python
# config.py
SHAPEFILE_PATH = None  # Will skip boundary overlay
```

---

## ğŸ“ˆ Output Examples

### KDE Heatmap
Shows density concentration areas - useful for identifying major activity zones.

### Voronoi Diagram
Divides space into territories - good for regional analysis.

### Engagement Contours
Isolines show engagement intensity gradients across the city.

### Hexagonal Grid
Regular hexagons for consistent spatial aggregation (recommended for statistics).

---

## ğŸ› ï¸ Troubleshooting

### Issue: "Module not found" error
```bash
pip install -r requirements.txt
```

### Issue: "Invalid API token"
- Verify token in `config.py`
- Check token hasn't expired
- Ensure Bearer prefix is included

### Issue: "No shapefiles found"
- Verify path in `config.py`
- Check all required files present (.shp, .shx, .dbf)
- Visualizer will use data extent as fallback

### Issue: "Memory error" during visualization
- Reduce `gridsize` in hexbin visualization
- Reduce `gridsize` in KDE interpolation (from 100j to 50j)
- Process data in smaller batches

### Issue: "No tweets collected"
- Check keyword list is non-empty
- Verify API token is valid
- Check location coordinates are formatted: `lat,lon,radius`
- Wait 30 minutes and retry (API rate limits)

---

## ğŸ“š Citation

If you use this project in research, please cite:

```bibtex
@software{urban_landuse_2025,
  author = {Your Name},
  title = {Urban Land-Use Classification Using Social Media Data},
  year = {2025},
  url = {https://github.com/yourusername/urban-land-use-analysis}
}
```

Or cite the research paper:
```
Author, A., & Author, B. (2025). Social media-based urban land-use 
classification using zero-shot topic modeling. Journal of Geospatial 
Analysis, 15(3), 234-256.
```

---

## ğŸ“ License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Areas for Contribution
- Additional visualization types
- Sentiment analysis integration
- Real-time streaming improvements
- BERTopic integration for topic modeling
- Unit test coverage
- Documentation improvements

---

## ğŸ› Bug Reports

Found a bug? [Open an issue](../../issues) with:
- Python version & OS
- Error message & traceback
- Steps to reproduce
- Your `config.py` (with token removed)

---

## ğŸ“§ Contact & Support

**Author:** Your Name  
**Institution:** Indian Institute of Technology Roorkee (IITR)  
**Email:** yourname@iitr.ac.in  
**Research Area:** Geospatial Analysis, Social Media Mining, Urban Computing

---

## ğŸ™ Acknowledgments

- Twitter API for providing access to social data
- GeoPandas team for geospatial tools
- IITR for research support

---

## ğŸ“– References

1. Arribas-Bel, D., et al. (2021). Open data products as foundation for creating value in smart cities. *Future Internet*, 13(3), 77.
2. Hasan, S., et al. (2019). Real-time estimation of near-future urban mobility. *Transportation Research Part C*, 107, 44-60.
3. Hochman, N., & Manovich, L. (2013). Zooming into Instagram. *First Monday*, 18(7).

---

**â­ If you find this project helpful, please star it!**

Last Updated: December 2025
